<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sampling and Lebesgue–Stieltjes Integration</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f5f5f5;
            color: #333;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 20px 0;
            text-align: center;
        }
        h1 {
            margin: 0;
            font-size: 2.5em;
        }
        main {
            max-width: 800px;
            margin: 40px auto;
            background-color: #fff;
            padding: 20px;
            box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
        }
        h2 {
            color: #2980b9;
            margin-top: 20px;
        }
        p {
            margin-bottom: 15px;
            font-size: 1.1em;
            line-height: 1.8;
        }
        code {
            background-color: #e7f4f9;
            color: #34495e;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 1.1em;
        }
        ul {
            margin: 20px 0;
            padding-left: 20px;
        }
        li {
            margin-bottom: 10px;
        }
        footer {
            text-align: center;
            padding: 20px 0;
            color: #777;
            font-size: 0.9em;
        }
    </style>
</head>
<body>

<header>
    <h1>Sampling Mean and Variance & Lebesgue–Stieltjes Integration</h1>
</header>

<main>
    <h2>1. General Concept of Sampling Mean and Variance</h2>
    <p>
        In probability and statistics, the <strong>sampling mean</strong> and <strong>variance</strong> are two essential concepts used to describe data derived from a population sample.
    </p>
    <ul>
        <li>
            <strong>Sampling Mean:</strong> The sampling mean is the average of a set of observations. It is calculated as:
            \[
            \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i
            \]
            where \( x_i \) represents individual sample values and \( n \) is the sample size.
        </li>
        <li>
            <strong>Sampling Variance:</strong> The sampling variance measures the spread of the data. It is calculated as:
            \[
            s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2
            \]
            where \( \bar{x} \) is the sampling mean.
        </li>
    </ul>
    <p>
        <strong>Key Features of Their Distributions:</strong>
        <ul>
            <li>The mean of the sampling distribution of the mean equals the population mean \( \mu \).</li>
            <li>The variance of the sampling distribution of the mean decreases as the sample size increases (inversely proportional to \( n \)).</li>
            <li>The Central Limit Theorem ensures that the sampling mean approaches a normal distribution as \( n \) grows large, regardless of the population distribution.</li>
        </ul>
    </p>

    <h2>2. General Idea of Lebesgue–Stieltjes Integration</h2>
    <p>
        The <strong>Lebesgue–Stieltjes integral</strong> generalizes the Riemann integral and is particularly useful in probability theory and measure theory.
    </p>
    <p>
        The integral is defined with respect to a function \( F \), which is non-decreasing and bounded. For a function \( f \), the Lebesgue–Stieltjes integral is:
        \[
        \int_a^b f(x) \, dF(x)
        \]
        Here, \( dF(x) \) can represent a probability measure or a cumulative distribution function (CDF).
    </p>
    <h3>Applications to Probability Theory</h3>
    <ul>
        <li>The Lebesgue–Stieltjes integral is used to define expectations of random variables. For example:
        \[
        \mathbb{E}[X] = \int_{-\infty}^\infty x \, dF(x)
        \]
        where \( F(x) \) is the CDF of \( X \).</li>
        <li>It allows integration with respect to discrete, continuous, or mixed distributions seamlessly.</li>
        <li>It simplifies working with probability measures in abstract spaces.</li>
    </ul>

    <h3>Applications to Measure Theory</h3>
    <ul>
        <li>Measure theory provides a rigorous foundation for probability, using the Lebesgue–Stieltjes integral to generalize summation and integration.</li>
        <li>It is crucial for defining concepts like Lebesgue measure and proving theorems such as the Dominated Convergence Theorem.</li>
        <li>It enables working with complex spaces where classical Riemann integration fails, such as unbounded or non-continuous domains.</li>
    </ul>

    <h2>3. Numerical Comparison of Lebesgue and Riemann Integrals</h2>
    <p>
        To understand the difference between the Lebesgue and Riemann integrals, consider the task of finding the expected value \( \mathbb{E}[X] \) of a random variable \( X \) with the following probability density function (PDF):
    </p>
    <p>
        \[ f(x) = \begin{cases} 
        3x^2 & \text{if } 0 \leq x \leq 1 \\
        0 & \text{otherwise.} 
        \end{cases} \]
    </p>
    <h3>Problem:</h3>
    <p>
        Compute \( \mathbb{E}[X] \) using both Riemann and Lebesgue approaches.
    </p>
    <h3>Solution:</h3>
    <h4>Using Riemann Integral:</h4>
    <p>
        Divide the domain of \( f(x) \), \([0, 1]\), into small intervals \( [x_i, x_{i+1}] \) and approximate \( \mathbb{E}[X] \) as:
        
        \[
        \mathbb{E}[X] = \int_0^1 x f(x) \, dx = \int_0^1 x \cdot 3x^2 \, dx = \int_0^1 3x^3 \, dx.
        \]
        Computing this integral:
        
        \[
        \int_0^1 3x^3 \, dx = 3 \cdot \frac{x^4}{4} \Big|_0^1 = 3 \cdot \frac{1}{4} = \frac{3}{4}.
        \]
    </p>
    <h4>Using Lebesgue Integral:</h4>
    <p>
        The Lebesgue integral partitions the range of \( f(x) \) instead of the domain. The expected value is given by:
        
        \[
        \mathbb{E}[X] = \int_0^1 x \, dF(x),
        \]
        where \( F(x) \) is the cumulative distribution function (CDF) of \( f(x) \). First, compute \( F(x) \):
        
        \[
        F(x) = \int_0^x 3t^2 \, dt = \left[ t^3 \right]_0^x = x^3.
        \]
        Now compute \( \mathbb{E}[X] \):
        
        \[
        \mathbb{E}[X] = \int_0^1 x \, d(x^3).
        \]
        Using integration by parts:
        
        \[
        \int_0^1 x \, d(x^3) = \Big[x \cdot x^3 \Big]_0^1 - \int_0^1 x^3 \, dx = \Big[1^4 - 0^4\Big] - \int_0^1 x^3 \, dx.
        \]
        The second term is:
        
        \[
        \int_0^1 x^3 \, dx = \frac{x^4}{4} \Big|_0^1 = \frac{1}{4}.
        \]
        Thus:
        
        \[
        \mathbb{E}[X] = 1 - \frac{1}{4} = \frac{3}{4}.
        \]
    </p>
    <h3>Conclusion:</h3>
    <p>
        Both methods yield the same result, \( \mathbb{E}[X] = \frac{3}{4} \). The Riemann integral divides the domain into intervals, while the Lebesgue integral considers the contributions of ranges of \( f(x) \) directly, which is especially advantageous for discontinuous or more complex functions.
    </p>
</main>

<footer>
    <p>&copy; 2024 Sampling and Integration Concepts. All Rights Reserved.</p>
</footer>

</body>
</html>